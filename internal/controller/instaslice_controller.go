/*
Copyright 2024.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package controller

import (
	"context"
	"fmt"
	"regexp"
	"strings"
	"time"

	inferencev1alpha1 "codeflare.dev/instaslice/api/v1alpha1"
	"github.com/go-logr/logr"
	v1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/api/errors"
	"k8s.io/apimachinery/pkg/runtime"
	"k8s.io/client-go/kubernetes"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/log"
	"sigs.k8s.io/controller-runtime/pkg/reconcile"
)

// InstasliceReconciler reconciles a Instaslice object
type InstasliceReconciler struct {
	client.Client
	Scheme     *runtime.Scheme
	kubeClient *kubernetes.Clientset
}

// AllocationPolicy interface with a single method
type AllocationPolicy interface {
	SetAllocationDetails(profileName string, newStart, size uint32, podUUID string, nodename string, processed string, discoveredGiprofile int, Ciprofileid int, Ciengprofileid int, namespace string, podName string, gpuUuid string) *inferencev1alpha1.AllocationDetails
}

type RightToLeftPolicy struct{}

type LeftToRightPolicy struct{}

type FirstFitPolicy struct{}

//+kubebuilder:rbac:groups=inference.codeflare.dev,resources=instaslices,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups=inference.codeflare.dev,resources=instaslices/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=inference.codeflare.dev,resources=instaslices/finalizers,verbs=update
//+kubebuilder:rbac:groups="",resources=pods,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups="",resources=nodes,verbs=get;list;watch;create;update;patch;delete

// Reconcile is part of the main kubernetes reconciliation loop which aims to
// move the current state of the cluster closer to the desired state.
// TODO(user): Modify the Reconcile function to compare the state specified by
// the Instaslice object against the actual cluster state, and then
// perform operations to make the cluster state reflect the state specified by
// the user.
//
// For more details, check Reconcile and its Result here:
// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.17.2/pkg/reconcile

func (r *InstasliceReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
	_ = log.FromContext(ctx)
	logger := log.Log.WithName("InstaSlice-controller")
	var policy AllocationPolicy
	policy = &FirstFitPolicy{}
	pod := &v1.Pod{}
	//var podName string
	var isPodGated = false
	err := r.Get(ctx, req.NamespacedName, pod)
	if err != nil {
		if errors.IsNotFound(err) {
			// Pod not found. It might have been deleted.
			return ctrl.Result{}, nil
		}
		// Error fetching the Pod
		return ctrl.Result{}, err
	}

	isPodGated = checkIfPodGated(pod, isPodGated)

	//Iterate through all InstaSlice objects in the cluster
	//Find allocation that belongs to pod and if processed is set to true
	//then the allocation should already be prepared for the pod, only in such
	//scenario ungate the pod.

	var instasliceList inferencev1alpha1.InstasliceList

	if err := r.List(ctx, &instasliceList, &client.ListOptions{}); err != nil {
		logger.Error(err, "Error listing Instaslice")
	}

	if !pod.DeletionTimestamp.IsZero() {
		for _, instaslice := range instasliceList.Items {
			for key, allocations := range instaslice.Spec.Allocations {
				if allocations.PodUUID == string(pod.UID) && allocations.Allocationstatus == "created" {
					//r.unGatePod(context.TODO(), pod.Name, req, pod, logger)
					//update allocation with status as deleting
					allocations.Allocationstatus = "deleting"
					instaslice.Spec.Allocations[key] = allocations
					if err := r.Update(ctx, &instaslice); err != nil {
						logger.Error(err, "Error updating instaslice allocations")
						return ctrl.Result{}, err
					}
				}
			}
		}

	}
	if isPodGated {
		for _, instaslice := range instasliceList.Items {
			for _, allocations := range instaslice.Spec.Allocations {
				if allocations.PodUUID == string(pod.UID) && allocations.Allocationstatus == "created" {
					r.unGatePod(context.TODO(), pod.Name, pod, logger)
					return ctrl.Result{}, nil
				}
				if allocations.PodUUID == string(pod.UID) && allocations.Allocationstatus == "creating" {
					return reconcile.Result{RequeueAfter: 5 * time.Second}, nil
				}
			}
		}

		//Assume pod only has one container with one GPU requests
		limits := pod.Spec.Containers[0].Resources.Limits
		profileName := r.extractProfileName(limits)
		logger.Info("The profile name obtained", "name", profileName)

		for _, instaslice := range instasliceList.Items {

			if instaslice.Status.Processed == "true" {
				_, reportError, result, errSelectingDevice := r.findDeviceForASlice(ctx, instaslice, profileName, policy, pod, logger)
				if reportError {
					return result, errSelectingDevice
				}

				return reconcile.Result{RequeueAfter: 10 * time.Second}, nil
			}

		}

	}

	return ctrl.Result{}, nil
}

func (r *InstasliceReconciler) findDeviceForASlice(ctx context.Context, instaslice inferencev1alpha1.Instaslice, profileName string, policy AllocationPolicy, pod *v1.Pod, logger logr.Logger) (string, bool, reconcile.Result, error) {
	//TODO: discover this value, this may work for A100 and H100 for now.
	for gpuuuid, _ := range instaslice.Spec.MigGPUUUID {
		if instaslice.Spec.Allocations == nil {
			instaslice.Spec.Allocations = make(map[string]inferencev1alpha1.AllocationDetails)
		}
		newStart := r.getStartIndexFromPreparedState(instaslice, gpuuuid, profileName)
		//size cannot be 9 atleast for A100s 40GB/80GB and H100 variants
		notValidIndex := uint32(9)
		if newStart == notValidIndex {
			//Move to next GPU
			continue
		}
		size, discoveredGiprofile, Ciprofileid, Ciengprofileid := r.extractGpuProfile(instaslice, profileName)
		allocDetails := policy.SetAllocationDetails(profileName, uint32(newStart), uint32(size),
			string(pod.UID), instaslice.Name, "creating", discoveredGiprofile,
			Ciprofileid, Ciengprofileid, pod.Namespace, pod.Name, gpuuuid)
		instaslice.Spec.Allocations[string(pod.UID)] = *allocDetails
		if err := r.Update(ctx, &instaslice); err != nil {
			logger.Error(err, "Error updating instaslice allocations")
			return "", true, ctrl.Result{}, err
		}
		return gpuuuid, false, reconcile.Result{}, nil
	}
	return "", false, reconcile.Result{}, fmt.Errorf("No valid GPU found that can fit slice")
}

// Extract profile name from the container limits spec
func (*InstasliceReconciler) extractProfileName(limits v1.ResourceList) string {
	profileName := ""
	for k, _ := range limits {
		if strings.Contains(k.String(), "nvidia") {

			re := regexp.MustCompile(`(\d+g\.\d+gb)`)
			match := re.FindStringSubmatch(k.String())
			if len(match) > 1 {
				profileName = match[1]
			} else {
				log.Log.Info("No match found")
			}
		}
	}
	return profileName
}

// Extract NVML specific attributes for GPUs, this will change for different generations of the GPU.
func (*InstasliceReconciler) extractGpuProfile(instaslice inferencev1alpha1.Instaslice, profileName string) (int, int, int, int) {
	var size int
	var discoveredGiprofile int
	var Ciprofileid int
	var Ciengprofileid int
	for _, item := range instaslice.Spec.Migplacement {
		if item.Profile == profileName {
			for _, aPlacement := range item.Placements {
				size = aPlacement.Size
				discoveredGiprofile = item.Giprofileid
				Ciprofileid = item.CIProfileID
				Ciengprofileid = item.CIEngProfileID
				break
			}
		}
	}
	return size, discoveredGiprofile, Ciprofileid, Ciengprofileid
}

// accounting logic that finds the correct GPU and index where a slice could be placed.
func (*InstasliceReconciler) getStartIndexFromPreparedState(instaslice inferencev1alpha1.Instaslice, gpuUUID string, profileName string) uint32 {
	//TODO: generalize, A100 and H100 have 8 indexes for 3g and 7g and 7 for rest, so go with 8 and we are bounded by
	//only valid placement indexes for a profile.
	var gpuAllocatedIndex [8]uint32
	// clean slate init
	for i := range gpuAllocatedIndex {
		gpuAllocatedIndex[i] = 0
	}
	for _, item := range instaslice.Spec.Prepared {
		if item.Parent == gpuUUID {
			for i := 0; i < int(item.Size); i++ {
				gpuAllocatedIndex[int(item.Start)+i] = 1
			}

		}
	}

	var neededContinousSlot int
	var possiblePlacements []int
	for _, placement := range instaslice.Spec.Migplacement {
		if placement.Profile == profileName {
			neededContinousSlot = placement.Placements[0].Size
			for _, placement := range placement.Placements {
				possiblePlacements = append(possiblePlacements, placement.Start)
			}
			break
		}
	}
	//TODO: generalize for other hardware models like A30, no slices can be placed on 9th index
	//if we return 9 then assume no valid index is found.
	var newStart = uint32(9)
	for _, value := range possiblePlacements {
		if gpuAllocatedIndex[value] == 0 {
			if neededContinousSlot == 1 {
				newStart = uint32(value)
				break
			}
			if neededContinousSlot == 2 {
				if value+neededContinousSlot < len(gpuAllocatedIndex) {
					if gpuAllocatedIndex[value] == 0 && gpuAllocatedIndex[value+1] == 0 {
						newStart = uint32(value)
						break
					}
				}

			}
			if neededContinousSlot == 4 {
				if value+neededContinousSlot < len(gpuAllocatedIndex) {
					if gpuAllocatedIndex[value] == 0 && gpuAllocatedIndex[value+1] == 0 && gpuAllocatedIndex[value+2] == 0 && gpuAllocatedIndex[value+3] == 0 {
						newStart = uint32(value)
						break
					}
				}
			}

			if neededContinousSlot == 8 {
				//special case
				if value+neededContinousSlot < len(gpuAllocatedIndex) {
					if gpuAllocatedIndex[value] == 0 && gpuAllocatedIndex[value+1] == 0 &&
						gpuAllocatedIndex[value+2] == 0 && gpuAllocatedIndex[value+3] == 0 &&
						gpuAllocatedIndex[value+4] == 0 && gpuAllocatedIndex[value+5] == 0 &&
						gpuAllocatedIndex[value+6] == 0 && gpuAllocatedIndex[value+7] == 0 {
						newStart = uint32(value)
					}
				}
			}
		}

	}

	return newStart
}

func checkIfPodGated(pod *v1.Pod, isPodGated bool) bool {
	for _, gate := range pod.Spec.SchedulingGates {
		if gate.Name == "org.instaslice/accelarator" {
			if pod.Status.Phase == v1.PodPending && strings.Contains(pod.Status.Conditions[0].Message, "blocked") {
				isPodGated = true
			}
		}
	}
	return isPodGated
}

// SetupWithManager sets up the controller with the Manager.
func (r *InstasliceReconciler) SetupWithManager(mgr ctrl.Manager) error {

	restConfig := mgr.GetConfig()

	var err error
	r.kubeClient, err = kubernetes.NewForConfig(restConfig)
	if err != nil {
		return err
	}

	return ctrl.NewControllerManagedBy(mgr).
		For(&v1.Pod{}).Named("InstaSlice-controller").
		Complete(r)
}

func (r *InstasliceReconciler) unGatePod(ctx context.Context, podName string, podUpdate *v1.Pod, logger logr.Logger) {
	err := r.Client.Get(ctx, client.ObjectKey{Name: podName, Namespace: podUpdate.Namespace}, podUpdate)
	if err != nil {
		//TODO: handle error condition
		logger.Error(err, "Failed to obtain pod from API server")
	}
	for i, gate := range podUpdate.Spec.SchedulingGates {
		if gate.Name == "org.instaslice/accelarator" {
			podUpdate.Spec.SchedulingGates = append(podUpdate.Spec.SchedulingGates[:i], podUpdate.Spec.SchedulingGates[i+1:]...)
		}
	}
	errUngating := r.Update(ctx, podUpdate)
	if errUngating != nil {
		logger.Error(errUngating, "Failed to ungate the pod")
	}
}

// Policy based allocation - FirstFit
func (r *FirstFitPolicy) SetAllocationDetails(profileName string, newStart, size uint32, podUUID, nodename string,
	processed string, discoveredGiprofile int, Ciprofileid int, Ciengprofileid int,
	namespace string, podName string, gpuUuid string) *inferencev1alpha1.AllocationDetails {
	return &inferencev1alpha1.AllocationDetails{
		Profile:          profileName,
		Start:            uint32(newStart),
		Size:             uint32(size),
		PodUUID:          podUUID,
		Nodename:         nodename,
		Allocationstatus: processed,
		Giprofileid:      discoveredGiprofile,
		CIProfileID:      Ciprofileid,
		CIEngProfileID:   Ciengprofileid,
		Namespace:        namespace,
		PodName:          podName,
		GPUUUID:          gpuUuid,
	}
}

// Policy based allocation - LeftToRIght
func (l *LeftToRightPolicy) SetAllocationDetails(profileName string, newStart, size uint32, podUUID, nodename string,
	processed string, discoveredGiprofile int, Ciprofileid int, Ciengprofileid int,
	namespace string, podName string, gpuUuid string) *inferencev1alpha1.AllocationDetails {
	// Implement the left-to-right policy here
	return &inferencev1alpha1.AllocationDetails{}
}

// Policy based allocation - RigghToLeft
func (l *RightToLeftPolicy) SetAllocationDetails(profileName string, newStart, size uint32, podUUID, nodename string,
	processed string, discoveredGiprofile int, Ciprofileid int, Ciengprofileid int,
	namespace string, podName string, gpuUuid string) *inferencev1alpha1.AllocationDetails {
	// Implement the left-to-right policy here
	return &inferencev1alpha1.AllocationDetails{}
}
